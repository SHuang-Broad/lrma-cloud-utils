{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "output_root_dir = ''\n",
    "gcs_record_keeping_bucket = ''\n",
    "gcs_record_keeping_dir = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This is the under-dev notebook for checking identity metadata of PacBio flowcells.\n",
    "\n",
    "The order of execution is the following:\n",
    "\n",
    "0. Load all flowcells that is workable\n",
    "1. Based on the flowcells' marked identity metadata, see if its Mercury FP VCF has been uploaded to the cloud database (and upload using on-prem scripts if missing)\n",
    "2. Check which flowcells have negative LOD, report\n",
    "3. Check which flowcells have indecisive LOD, report\n",
    "4. Check which flowcells don't have LOD yet, then\n",
    "    * if it's ready, i.e. have alignments and FP vcf, then launch `VerifyFingerprint`\n",
    "    * if it's because there's no BAM yet, i.e. `PBFlowcell` hasn't been run on it, launch the job\n",
    "    * if it's because there's a shallow BAM, report\n",
    "\n",
    "There are several dark-knowledge dependencies that are needed for this to run:\n",
    "    * \"known_samples_without_mercury.txt\": holding samples that are known to have no GT'ed fingerprinting VCF\n",
    "    * \"known_flowcells_with_issues.txt\": holding flowcells that are known to be inappropriate (for various reasons) to be fingerprinted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "from dateutil import parser\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from google.cloud import storage\n",
    "storage_client = storage.Client()\n",
    "import pprint\n",
    "from termcolor import colored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lrmaCU.gcs_utils import *\n",
    "from lrmaCU.utils import *\n",
    "\n",
    "from lrmaCU.terra.table_utils import *\n",
    "from lrmaCU.terra.submission.submission_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Date & time, for record keeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "today = datetime.datetime.today().strftime(\"%Y%m%d\")\n",
    "cutoff_date = pd.to_datetime(datetime.datetime(2021, 1, 1, 0, 0, tzinfo=datetime.timezone.utc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Current Time =\", datetime.datetime.now().strftime(\"%D %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "output_root_dir = output_root_dir.rstrip('/')\n",
    "gcs_record_keeping_dir = gcs_record_keeping_dir.rstrip('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "output_dir = f'{output_root_dir}/{datetime.datetime.today().strftime(\"%Y-%m-%d\")}'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logger = get_configured_logger(log_level=logging.INFO)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Filters to apply, still under development, so changes with time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "known_flowcells_inappropriate_for_current_pbflowcell = ['DA143934', 'DA073901']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ff = GcsPath('gs://broad-gp-pacbio/metrics/fingerprinting/mercury/known_samples_without_mercury.txt')\n",
    "if not ff.exists(storage_client):\n",
    "    raise RuntimeError(\"Dependency file gs://broad-gp-pacbio/metrics/fingerprinting/mercury/known_samples_without_mercury.txt doesn't exist any more.\")\n",
    "known_samples_without_mercury = ff.get_blob(storage_client).download_as_text().split('\\n')\n",
    "print(f\"{len(known_samples_without_mercury)} samples are known to have no Mercury entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ff = GcsPath('gs://broad-gp-pacbio/metrics/fingerprinting/mercury/known_flowcells_with_issues.txt')\n",
    "if not ff.exists(storage_client):\n",
    "    raise RuntimeError(\"Dependency file gs://broad-gp-pacbio/metrics/fingerprinting/mercury/known_flowcells_with_issues.txt doesn't exist any more.\")\n",
    "known_problematic_flowcells = ff.get_blob(storage_client).download_as_text().split('\\n')\n",
    "print(f\"{len(known_problematic_flowcells)} flowcells known to have issues preventing them from being VerifyFingerprint'ed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ff = GcsPath('gs://broad-gp-pacbio/metrics/fingerprinting/mercury/flowcells_identity_manually_confirmed.txt')\n",
    "if not ff.exists(storage_client):\n",
    "    raise RuntimeError(\"Dependency file gs://broad-gp-pacbio/metrics/fingerprinting/mercury/flowcells_identity_manually_confirmed.txt doesn't exist any more.\")\n",
    "borderline_lod_flowcells_cleared = ff.get_blob(storage_client).download_as_text().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "samples_in_cloud_mercury = list()\n",
    "for b in storage_client.list_blobs('broad-gp-pacbio', prefix='metrics/fingerprinting/mercury/vcfs'):\n",
    "    file_name = b.name.split('/')[-1]\n",
    "    if file_name.endswith('.vcf.gz'):\n",
    "        sample = file_name.split('__')[0]\n",
    "        samples_in_cloud_mercury.append(sample)\n",
    "print(f\"{len(samples_in_cloud_mercury)} samples already in living in the lrma-cloud-mercury.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ff = GcsPath('gs://broad-gp-pacbio/metrics/fingerprinting/notifiers.tsv')\n",
    "if not ff.exists(storage_client):\n",
    "    raise RuntimeError(\"Dependency file gs://broad-gp-pacbio/metrics/fingerprinting/notifiers.txt doesn't exist any more.\")\n",
    "ll = [tuple(line.split('\\t')) for line in ff.get_blob(storage_client).download_as_text().split('\\n') if line]\n",
    "notification_receiver_names, notification_receiver_emails = zip(*ll)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ff = GcsPath('gs://broad-dsde-methods-long-reads/resources/developers.tsv')\n",
    "if not ff.exists(storage_client):\n",
    "    raise RuntimeError(\"Dependency file gs://broad-dsde-methods-long-reads/resources/developers.tsv doesn't exist any more.\")\n",
    "ll = [tuple(line.split('\\t')) for line in ff.get_blob(storage_client).download_as_text().split('\\n') if line]\n",
    "developer_names, developer_emails = zip(*ll)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD & FORMAT FLOWCELLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "primary_namespace = 'production-long-reads'\n",
    "primary_workspace = 'broad-gp-pacbio'\n",
    "root_data_type='sample'\n",
    "flowcell_table = \\\n",
    "  fetch_existing_root_table(ns=primary_namespace,\n",
    "                            ws=primary_workspace,\n",
    "                            etype=root_data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_submission_type = root_data_type + '_submission_batch'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gcs_locations = ['aligned_bai', 'aligned_bam', 'aligned_pbi',\n",
    "                 'ccs_bam', 'ccs_pbi', 'ccs_report',\n",
    "                 'fingerprint_details', 'fingerprint_metrics',\n",
    "                 'fq', 'gcs_input_dir', 'input_bam', 'input_pbi', 'subreads_bam', 'subreads_pbi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lab_identity = ['bio_sample', 'description', 'well_sample']\n",
    "sequencer_identity = ['flowcell_id', 'movie_name', 'well_name']\n",
    "terra_identity = ['sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "categorical_columns = {'type': 'category',\n",
    "                       'columns': ['application', 'experiment_type', 'instrument', 'workspace']}\n",
    "\n",
    "date_time_columns = {'type': 'datetime64',\n",
    "                     'timezone': datetime.timezone.utc,\n",
    "                     'columns': ['created_at']}\n",
    "\n",
    "boolean_columns = {'type': 'bool',\n",
    "                   'columns': ['is_ccs', 'is_corrected', 'is_isoseq']}\n",
    "\n",
    "int_type_columns = {'type': 'Int64',\n",
    "                    'columns': ['aligned_num_bases','aligned_num_reads','aligned_read_length_N50',\n",
    "                                'ccs_zmws_fail_filters','ccs_zmws_input','ccs_zmws_pass_filters', 'ccs_zmws_shortcut_filters',\n",
    "                                'insert_size',\n",
    "                                'num_bases','num_reads','num_reads_Q10','num_reads_Q12','num_reads_Q15','num_reads_Q5','num_reads_Q7','num_records',\n",
    "                                'total_length']}\n",
    "\n",
    "float_type_columns = {'type': 'float64',\n",
    "                      'columns': ['lod_expected_sample',\n",
    "                                  'aligned_est_fold_cov', 'raw_est_fold_cov',\n",
    "                                  'aligned_frac_bases','aligned_read_length_mean','aligned_read_length_median','aligned_read_length_stdev',\n",
    "                                  'average_identity', 'median_identity',\n",
    "                                  'ccs_zmws_fail_filters_pct','ccs_zmws_pass_filters_pct','ccs_zmws_shortcut_filters_pct',\n",
    "                                  'polymerase_read_length_N50', 'polymerase_read_length_mean',\n",
    "                                  'read_length_N50', 'read_length_mean', 'read_length_median', 'read_length_stdev', 'read_qual_mean', 'read_qual_median',\n",
    "                                  'subread_read_length_N50','subread_read_length_mean']}\n",
    "\n",
    "string_type_columns = {'type': 'str',\n",
    "                       'columns': gcs_locations + terra_identity + lab_identity + sequencer_identity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for n in boolean_columns['columns']:\n",
    "    flowcell_table[n] = flowcell_table[n].apply(lambda s: s=='TRUE' or s=='True' or s=='true').astype(boolean_columns['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for n in categorical_columns['columns']:\n",
    "    flowcell_table[n] = flowcell_table[n].astype(categorical_columns['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for n in string_type_columns['columns']:\n",
    "    flowcell_table[n] = flowcell_table[n].astype(string_type_columns['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_float(e) -> float or None:\n",
    "    if e:\n",
    "        if e.lower() in ['nan', 'none']:\n",
    "            return None\n",
    "        else:\n",
    "            try:\n",
    "                return float(e)\n",
    "            except TypeError:\n",
    "                print(e)\n",
    "                raise\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def convert_to_int(e) -> int:\n",
    "    f = convert_to_float(e)\n",
    "    return round(f) if f else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for n in int_type_columns['columns']:\n",
    "    try:\n",
    "        flowcell_table[n] = flowcell_table[n].apply(convert_to_int).astype(int_type_columns['type'])\n",
    "    except ValueError:\n",
    "        print(n)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for n in float_type_columns['columns']:\n",
    "    try:\n",
    "        flowcell_table[n] = flowcell_table[n].apply(convert_to_float).astype(float_type_columns['type'])\n",
    "    except ValueError:\n",
    "        print(n)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_date_time(s):\n",
    "    try:\n",
    "        t = parser.isoparse(s).astimezone(tz=date_time_columns['timezone'])\n",
    "        return pd.to_datetime(t)\n",
    "    except (ValueError, pd.errors.OutOfBoundsDatetime):\n",
    "        return pd.Timestamp.min\n",
    "for n in date_time_columns['columns']:\n",
    "    flowcell_table[n] = flowcell_table[n].apply(lambda s: pd.to_datetime(convert_date_time(s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# FILTER DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def filter_pacbio_flowcells(terra_table_row, cutoff_date_to_study,\n",
    "                            columns_and_blacklist: dict) -> bool:\n",
    "    \"\"\"\n",
    "    Filter applicable to all flowcells.\n",
    "    :param terra_table_row:\n",
    "    :param cutoff_date_to_study:\n",
    "    :param columns_and_blacklist:\n",
    "    :return: true if the row should be kept\n",
    "    \"\"\"\n",
    "\n",
    "    # filter out known bad ones\n",
    "    keep = True\n",
    "    for col, black_list in columns_and_blacklist.items():\n",
    "        keep &= terra_table_row[col] not in black_list\n",
    "\n",
    "    # no time zone information\n",
    "    sequencing_date = terra_table_row['created_at']\n",
    "    if sequencing_date.tzinfo is None:\n",
    "        return False\n",
    "\n",
    "    # remove unknowns\n",
    "    keep &= ' ' not in terra_table_row['description']\n",
    "    keep &= 'unknown' != terra_table_row['description']\n",
    "\n",
    "    # NON-genomic applications\n",
    "    keep &= not terra_table_row['description'].startswith('SIRV_')\n",
    "    keep &= 'amplicon' not in terra_table_row['application']\n",
    "\n",
    "    # too early\n",
    "    keep &= sequencing_date >= cutoff_date_to_study\n",
    "\n",
    "    return keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "my_blacklists = {'flowcell_id': [*known_problematic_flowcells , *known_flowcells_inappropriate_for_current_pbflowcell],\n",
    "                 'well_sample': known_samples_without_mercury,\n",
    "                 'experiment_type': ['ISOSEQ', 'MASSEQ'],\n",
    "                 'application': ['isoSeq', 'unknown']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "usable_flowcell_table = flowcell_table.loc[flowcell_table.apply(lambda row: filter_pacbio_flowcells(row, cutoff_date, my_blacklists), axis=1),:].reset_index(drop=True)\n",
    "usable_flowcell_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "usable_flowcell_table.loc[usable_flowcell_table['flowcell_id'].isin(known_problematic_flowcells),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"{len(usable_flowcell_table['well_sample'].unique())} unique SM-[A-Z0-9]+ samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "samples_upto_date = usable_flowcell_table[['bio_sample', 'description', 'well_sample']].sort_values(by=['well_sample']).drop_duplicates(ignore_index=True)\n",
    "samples_upto_date.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desired_columns_in_order = ['flowcell_id', 'bio_sample', 'description', 'well_sample',\n",
    "                            'aligned_est_fold_cov',\n",
    "                            'lod_expected_sample',  'aligned_bam',\n",
    "                            'application', 'experiment_type',\n",
    "                            'is_ccs', 'is_corrected', 'is_isoseq',\n",
    "                            'ccs_zmws_pass_filters_pct',\n",
    "                            'instrument', 'movie_name', 'well_name', 'insert_size', 'created_at',\n",
    "                            'sample', 'workspace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative LOD, i.e. swapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "swapped_flowcells = usable_flowcell_table[usable_flowcell_table.lod_expected_sample < -3.0].reset_index(drop=True).sort_values(by=['created_at'])\n",
    "swapped_flowcells[desired_columns_in_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "swapped_flowcells[desired_columns_in_order]\\\n",
    "    .to_csv(f'{output_dir}/negative.LOD.flowcells.tsv', sep='\\t', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indecisive LOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "indecisive_idx = ~usable_flowcell_table['flowcell_id'].isin( borderline_lod_flowcells_cleared)\n",
    "indecisive_idx &= ((usable_flowcell_table.lod_expected_sample >= -3) & (usable_flowcell_table.lod_expected_sample < 6))\n",
    "indecisive_flowcells = usable_flowcell_table[indecisive_idx].reset_index(drop=True).sort_values(by=['created_at'])\n",
    "indecisive_flowcells[desired_columns_in_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if 0 < len(indecisive_flowcells):\n",
    "    indecisive_flowcells[desired_columns_in_order]\\\n",
    "        .to_csv(f'{output_dir}/indecisive.LOD.flowcells.tsv',\n",
    "                sep='\\t', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No LOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "no_lod = usable_flowcell_table.loc[usable_flowcell_table.lod_expected_sample.isna(),:].reset_index(drop=True)\n",
    "print(f'{len(no_lod)} flowcell have no LOD.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "no_lod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "is_with_bam = no_lod['aligned_bam'].apply(lambda s: s.startswith('gs://'))\n",
    "is_enough_coverage = no_lod['aligned_est_fold_cov'].apply(lambda s: float(s) > 1.0)\n",
    "is_with_mercury = no_lod['well_sample'].isin(samples_in_cloud_mercury)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No LOD&mdash;meaningless coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shallow_bam = no_lod.loc[is_with_bam & ~is_enough_coverage].sort_values(by=['well_sample']).reset_index(drop=True)\n",
    "shallow_bam[desired_columns_in_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if 0 < len(shallow_bam):\n",
    "    shallow_bam.to_csv(f'{output_dir}/shallow.BAM.flowcells.tsv', sep='\\t', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No LOD&mdash;just need to run it. !!! WARN: NEED TO CHECK IT'S NOT RUNNING!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ready_to_fp = no_lod.loc[is_with_bam & is_enough_coverage & is_with_mercury].sort_values(by=['well_sample']).reset_index(drop=True)\n",
    "ready_to_fp[desired_columns_in_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# explicitly disable call caching because database updates almost daily\n",
    "if 0 < len(ready_to_fp):\n",
    "    verify_before_submit(primary_namespace, primary_workspace,\n",
    "                         workflow_name='VerifyFingerprint',\n",
    "                         etype=root_data_type, enames=ready_to_fp['sample'].tolist(),\n",
    "                         use_callcache=False,\n",
    "                         batch_type_name = 'dailynotebookrun_flowcell_batch', expression = 'this.samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No LOD&mdash;no BAM yet !!! WARN: NEED TO CHECK IT'S NOT RUNNING!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "need_bam = no_lod.loc[~is_with_bam].sort_values(by=['well_sample']).reset_index(drop=True)\n",
    "need_bam[desired_columns_in_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if 0 < len(need_bam):\n",
    "    verify_before_submit(primary_namespace, primary_workspace,\n",
    "                         workflow_name='PBFlowcell',\n",
    "                         etype=root_data_type, enames=need_bam['sample'].tolist(),\n",
    "                         use_callcache=True,\n",
    "                         batch_type_name = 'dailynotebookrun_sample_batch', expression = 'this.samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query on-prem Mercury, prep for next round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "need_mercury_sample_ids = \\\n",
    "    samples_upto_date.loc[~samples_upto_date['well_sample'].isin(samples_in_cloud_mercury), :]\\\n",
    "        .rename({'bio_sample': 'Collab_Part_ID',\n",
    "                 'description': 'Collab_SM_ID',\n",
    "                 'well_sample': 'Broad_LSID'\n",
    "                 }, axis=1)\\\n",
    "        .sort_values(by=['Broad_LSID'], axis=0)\\\n",
    "        .reset_index(drop=True)\n",
    "\n",
    "need_mercury_sample_ids['Broad_LSID'] = need_mercury_sample_ids['Broad_LSID'].apply(lambda s: re.sub('^SM-', '', s))\n",
    "\n",
    "need_mercury_sample_ids['Date'] = today\n",
    "\n",
    "print(f\"{len(need_mercury_sample_ids)} newly found samples need to have their FP VCFs queried.\")\n",
    "need_mercury_sample_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if 0 < len(need_mercury_sample_ids):\n",
    "    csv_location = f'{output_dir}/need_mercury_sample_ids_headerless.csv'\n",
    "    need_mercury_sample_ids.to_csv(csv_location,\n",
    "                                   sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !!! Now go and upload the VCFs... !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload to designated record-keeping bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base = output_dir.split('/')[-1]\n",
    "for f in absolute_file_paths(output_dir):\n",
    "    bf = os.path.basename(f)\n",
    "    upload_blob(gcs_record_keeping_bucket, f, f\"{gcs_record_keeping_dir}/{base}/{bf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Notification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if 0 < len(swapped_flowcells):\n",
    "    headline = f'PacBio flowcells failed fingerprint check as of {today}'\n",
    "    html = \"\"\"\\\n",
    "    <html>\n",
    "      <head></head>\n",
    "      <body>\n",
    "        {0}\n",
    "      </body>\n",
    "      </html>\n",
    "    \"\"\".format(swapped_flowcells[desired_columns_in_order].to_html())\n",
    "    msg = 'Please check'\n",
    "    # msg = swapped_flowcells[desired_columns_in_order].to_string(index=False)\n",
    "    send_notification(logger=logger, notification_sender_name = 'LRMA-AUTO-NOTIF',\n",
    "                      notification_receiver_names = notification_receiver_names, notification_receiver_emails = notification_receiver_emails,\n",
    "                      email_subject = headline, email_body = msg, html_body = html)\n",
    "\n",
    "if 0 < len(indecisive_flowcells):\n",
    "    headline = f'PacBio flowcells with indecisive fingerprint LOD as of {today}'\n",
    "    html = \"\"\"\\\n",
    "    <html>\n",
    "      <head></head>\n",
    "      <body>\n",
    "        {0}\n",
    "      </body>\n",
    "    </html>\n",
    "    \"\"\".format(indecisive_flowcells[desired_columns_in_order].to_html())\n",
    "    msg = 'Please check'\n",
    "    # msg = indecisive_flowcells[desired_columns_in_order].to_string(index=False)\n",
    "    send_notification(logger=logger, notification_sender_name = 'LRMA-AUTO-NOTIF',\n",
    "                      notification_receiver_names = notification_receiver_names, notification_receiver_emails = notification_receiver_emails,\n",
    "                      email_subject = headline, email_body = msg, html_body = html)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trace_back = 7\n",
    "failure_cnt_threshold = 3\n",
    "\n",
    "repeated_failures_PBFlowcell = get_repeatedly_failed_entities(primary_namespace, primary_workspace,\n",
    "                                                              'PBFlowcell', 'sample',\n",
    "                                                              trace_back, failure_cnt_threshold)\n",
    "repeated_failures_PBCCSIsoSeq = get_repeatedly_failed_entities(primary_namespace, primary_workspace,\n",
    "                                                               'PBCCSIsoSeq', 'sample_set',\n",
    "                                                               trace_back, failure_cnt_threshold)\n",
    "repeated_failures_PBCCSWholeGenome = get_repeatedly_failed_entities(primary_namespace, primary_workspace,\n",
    "                                                                    'PBCCSWholeGenome', 'sample_set',\n",
    "                                                                    trace_back, failure_cnt_threshold)\n",
    "repeated_failures_PBCLRWholeGenome = get_repeatedly_failed_entities(primary_namespace, primary_workspace,\n",
    "                                                                    'PBCLRWholeGenome', 'sample_set',\n",
    "                                                                    trace_back, failure_cnt_threshold)\n",
    "\n",
    "msg = ''\n",
    "if 0 < len(repeated_failures_PBFlowcell):\n",
    "    msg += colored(\"\\n\\nRepeated failures with PBFlowcell:\\n\", color='red', attrs=['bold']) + pprint.pformat(repeated_failures_PBFlowcell)\n",
    "if 0 < len(repeated_failures_PBCCSIsoSeq):\n",
    "    msg += colored(\"\\n\\nRepeated failures with PBCCSIsoSeq:\\n\", color='red', attrs=['bold']) + pprint.pformat(repeated_failures_PBCCSIsoSeq)\n",
    "if 0 < len(repeated_failures_PBCCSWholeGenome):\n",
    "    msg += colored(\"\\n\\nRepeated failures with PBCCSWholeGenome:\\n\", color='red', attrs=['bold']) + pprint.pformat(repeated_failures_PBCCSWholeGenome)\n",
    "if 0 < len(repeated_failures_PBCLRWholeGenome):\n",
    "    msg += colored(\"\\n\\nRepeated failures with PBCLRWholeGenome:\\n\", color='red', attrs=['bold']) + pprint.pformat(repeated_failures_PBCLRWholeGenome)\n",
    "\n",
    "if msg:\n",
    "    headline = f'Repeated failed workflows in workspace {primary_namespace}/{primary_workspace} as of {today}'\n",
    "    send_notification(logger=logger, notification_sender_name = 'LRMA-AUTO-NOTIF',\n",
    "                      notification_receiver_names = developer_names, notification_receiver_emails = developer_emails,\n",
    "                      email_subject = headline, email_body = msg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}